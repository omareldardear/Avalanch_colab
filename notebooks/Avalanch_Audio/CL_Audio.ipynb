{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Stratigies For Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your tourch audio dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==2.7.0\n",
      "  Obtaining dependency information for torch==2.7.0 from https://files.pythonhosted.org/packages/9c/58/2d245b6f1ef61cf11dfc4aceeaacbb40fea706ccebac3f863890c720ab73/torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchaudio==2.7.0\n",
      "  Obtaining dependency information for torchaudio==2.7.0 from https://files.pythonhosted.org/packages/78/98/ec8c7aba67b44cdc59717d4b43d02023ded5da180d33c6469d20bf5bfa3c/torchaudio-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch==2.7.0)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from torch==2.7.0) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from torch==2.7.0) (80.7.1)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0)\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.7.0)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from torch==2.7.0) (3.1.6)\n",
      "Collecting fsspec (from torch==2.7.0)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/44/4b/e0cfc1a6f17e990f3e64b7d941ddc4acdc7b19d6edd51abf495f32b1a9e4/fsspec-2025.3.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.6.77 from https://files.pythonhosted.org/packages/75/2e/46030320b5a80661e88039f59060d1790298b4718944a65a7f2aeda3d9e9/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.6.77 from https://files.pythonhosted.org/packages/e1/23/e717c5ac26d26cf39a27fbc076240fad2e3b817e5889d671b67f4f9f49c5/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.6.80 from https://files.pythonhosted.org/packages/49/60/7b6497946d74bcf1de852a21824d63baad12cd417db4195fc1bfe59db953/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==9.5.1.17 from https://files.pythonhosted.org/packages/2a/78/4535c9c7f859a64781e43c969a3a7e84c54634e319a996d43ef32ce46f83/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cublas-cu12==12.6.4.1 from https://files.pythonhosted.org/packages/af/eb/ff4b8c503fa1f1796679dce648854d58751982426e4e4b37d6fce49d259c/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cufft-cu12==11.3.0.4 from https://files.pythonhosted.org/packages/8f/16/73727675941ab8e6ffd86ca3a4b7b47065edcca7a997920b831f8147c99d/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-curand-cu12==10.3.7.77 from https://files.pythonhosted.org/packages/73/1b/44a01c4e70933637c93e6e1a8063d1e998b50213a6b65ac5a9169c47e98e/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cusolver-cu12==11.7.1.2 from https://files.pythonhosted.org/packages/f0/6e/c2cf12c9ff8b872e92b4a5740701e51ff17689c4d726fca91875b07f655d/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cusparse-cu12==12.5.4.2 from https://files.pythonhosted.org/packages/06/1e/b8b7c2f4099a37b96af5c9bb158632ea9e5d9d27d7391d7eb8fc45236674/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cusparselt-cu12==0.6.3 from https://files.pythonhosted.org/packages/3b/9a/72ef35b399b0e183bc2e8f6f558036922d453c4d8237dab26c666a04244b/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.26.2 from https://files.pythonhosted.org/packages/67/ca/f42388aed0fddd64ade7493dbba36e1f534d4e6fdbdd355c6a90030ae028/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-nvtx-cu12==12.6.77 from https://files.pythonhosted.org/packages/56/9a/fff8376f8e3d084cd1530e1ef7b879bb7d6d265620c95c1b322725c694f4/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12==12.6.85 from https://files.pythonhosted.org/packages/9d/d7/c5383e47c7e9bf1c99d5bd2a8c935af2b6d705ad831a7ec5c97db4d82f4f/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0)\n",
      "  Obtaining dependency information for nvidia-cufile-cu12==1.11.1.6 from https://files.pythonhosted.org/packages/b2/66/cc9876340ac68ae71b15c743ddb13f8b30d5244af344ec8322b449e35426/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch==2.7.0)\n",
      "  Obtaining dependency information for triton==3.3.0 from https://files.pythonhosted.org/packages/11/53/ce18470914ab6cfbec9384ee565d23c4d1c55f0548160b1c7b33000b11fd/triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.0)\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/src/robot/DardearGithub/Avalanch_colab/.venv/lib/python3.12/site-packages (from jinja2->torch==2.7.0) (3.0.2)\n",
      "Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 triton-3.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install torch==2.7.0 torchaudio==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class m_audio_dataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                    audio_dir,\n",
    "                    transformation,\n",
    "                    num_samples,\n",
    "                    pd_data,\n",
    "                    kind='train'):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.num_samples = num_samples\n",
    "        if (transformation):\n",
    "            self.transformation = transformation\n",
    "\n",
    "        if kind=='train':\n",
    "            self.items = pd_data[pd_data['train'] == True][['recordedName','label','className']]\n",
    "            self.items.reset_index(inplace = True,drop = True)\n",
    "        elif kind=='test':\n",
    "            self.items = pd_data[pd_data['train'] == False][['recordedName','label','className']]\n",
    "            self.items.reset_index(inplace = True,drop = True)\n",
    "\n",
    "        else:\n",
    "            self.items =  pd_data[['recordedName','label','className']]\n",
    "            self.items.reset_index(inplace = True,drop = True)\n",
    "\n",
    "        self.length = len(self.items)\n",
    "\n",
    "        self.targets = torch.as_tensor( list(self.items['label']))\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.items['recordedName'][index]\n",
    "        className = self.items['className'][index]\n",
    "        label = self.items['label'][index]\n",
    "        signal, rate = torchaudio.load(self.audio_dir+ className + '/' + filename)\n",
    "        signal = self._to_mono_if_necessary(signal)\n",
    "        signal = self._cutting_if_necessary(signal)\n",
    "        signal = self._padding_if_necessary(signal)\n",
    "        data_tensor = self.transformation(signal)\n",
    "        return (data_tensor, int(label))\n",
    "\n",
    "\n",
    "    def _to_mono_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _cutting_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _padding_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(setType=\"train\",\n",
    "                ballance=False,\n",
    "                FRAME_SIZE = 1024,\n",
    "                HOP_LENGTH = 512,\n",
    "                N_MELS = 60):\n",
    "\n",
    "    BASE_DIR = \"..\"\n",
    "    ANNOTATIONS_FILE = BASE_DIR + \"/recordingInfo/validRecordings.csv\"\n",
    "    AUDIO_DIR = BASE_DIR + \"/recordedAudio/\"\n",
    "\n",
    "    pd_data = pd.read_csv(ANNOTATIONS_FILE, index_col=0)\n",
    "    # adding label column\n",
    "    ord_enc = OrdinalEncoder()\n",
    "    pd_data[\"label\"] = ord_enc.fit_transform(pd_data[[\"className\"]]).astype(int)\n",
    "\n",
    "    # splittint train test\n",
    "    pd_data['train'] = False\n",
    "    trainPercent = 0.7\n",
    "    for labelVal in pd_data.label.unique():\n",
    "        trainCount = int(len(pd_data[pd_data.label == labelVal]) * trainPercent)\n",
    "        pd_data.loc[pd_data[pd_data.label == labelVal].head(trainCount).index, 'train'] = True\n",
    "    file = pd_data['recordedName'][0]\n",
    "    className = pd_data['className'][0]\n",
    "    fullName = AUDIO_DIR + className + '/' + file\n",
    "    data_array, samplerate = sf.read(fullName)\n",
    "\n",
    "\n",
    "    if(ballance):\n",
    "        minClassSize = min([len(pd_data[pd_data['label'] == 0]), len(pd_data[pd_data['label'] == 1]),\n",
    "                            len(pd_data[pd_data['label'] == 2]), len(pd_data[pd_data['label'] == 3])])\n",
    "        for i in range(4):\n",
    "            pd_data = pd_data.drop(pd_data[pd_data['label'] == i].index[minClassSize:])\n",
    "\n",
    "        pd_data = pd_data.reset_index(drop=True)\n",
    "        # splittint train test\n",
    "        pd_data['train'] = False\n",
    "        trainPercent = 0.7\n",
    "        for labelVal in pd_data.label.unique():\n",
    "            trainCount = int(len(pd_data[pd_data.label == labelVal]) * trainPercent)\n",
    "            pd_data.loc[pd_data[pd_data.label == labelVal].head(trainCount).index, 'train'] = True\n",
    "\n",
    "\n",
    "    SAMPLES_SIZE = int(5.8 * samplerate)\n",
    "    SAMPLE_RATE = samplerate\n",
    "\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=FRAME_SIZE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS,\n",
    "        normalized=True\n",
    "    )\n",
    "\n",
    "    return m_audio_dataset(AUDIO_DIR,\n",
    "                            mel_spectrogram,\n",
    "                            SAMPLES_SIZE,\n",
    "                            pd_data,\n",
    "                            kind=setType) , 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={}\n",
    "config['FRAME_SIZE'] = 1024\n",
    "config['HOP_LENGTH'] = 512\n",
    "config['N_MELS'] = 60\n",
    "\n",
    "config['lr_base'] = 0.1\n",
    "config['wght_decay'] = 1E-05\n",
    "config['momentum'] = 0.9\n",
    "config['memory_size'] = 2000\n",
    "\n",
    "config['batch_size'] = 32\n",
    "config['nb_exp'] = 4\n",
    "config['epochs'] = 2\n",
    "config['lr_milestones_1'] = 49\n",
    "config['lr_milestones_2'] = 63\n",
    "config['lr_factor'] = 5\n",
    "config['seed'] = 1234\n",
    "config['modelType'] = 'icarlNet'\n",
    "config['model_hs'] = 1000\n",
    "config['opt'] = 'ADAM'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, nb_exp = loadDataSet(\"train\",False,config['FRAME_SIZE'] ,config['HOP_LENGTH'] ,config['N_MELS'])\n",
    "test_data, nb_exp = loadDataSet(\"test\",False,config['FRAME_SIZE'] ,config['HOP_LENGTH'] ,config['N_MELS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'avalanche'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mavalanche\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbenchmarks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AvalancheDataset\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mavalanche\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbenchmarks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nc_benchmark\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mavalanche\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GDumb , ICaRL\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'avalanche'"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training import GDumb , ICaRL\n",
    "from avalanche.models import IcarlNet, make_icarl_net, initialize_icarl_net\n",
    "from avalanche.models import SimpleMLP, as_multitask\n",
    "from torch.optim import SGD , Adam\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import (\n",
    "    ExperienceAccuracy,\n",
    "    StreamAccuracy,\n",
    "    EpochAccuracy,\n",
    ")\n",
    "from avalanche.logging.interactive_logging import InteractiveLogger\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "import time\n",
    "import pandas as pd\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AvalancheDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_data_avalanche = \u001b[43mAvalancheDataset\u001b[49m(train_data)\n\u001b[32m      2\u001b[39m test_data_avalanche = AvalancheDataset(test_data)\n",
      "\u001b[31mNameError\u001b[39m: name 'AvalancheDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_avalanche = AvalancheDataset(train_data)\n",
    "test_data_avalanche = AvalancheDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  The benchmark\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "scenario = nc_benchmark(\n",
    "        train_dataset=train_data,\n",
    "        test_dataset=test_data,\n",
    "        n_experiences=config[\"nb_exp\"],\n",
    "        task_labels=False,\n",
    "        seed=config['seed'],\n",
    "        shuffle=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(inp):\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation , plugins, and loggers\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "\n",
    "evaluator = EvaluationPlugin(\n",
    "        EpochAccuracy(),\n",
    "        ExperienceAccuracy(),\n",
    "        StreamAccuracy(),\n",
    "        loggers=[InteractiveLogger()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The Model\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "\n",
    "if(config['modelType'] == \"icarlNet\"):\n",
    "    model = make_icarl_net(num_classes=config['nb_exp'],n=5, c=1)\n",
    "    model.apply(initialize_icarl_net)\n",
    "else:\n",
    "\n",
    "    model = SimpleMLP(num_classes=config['nb_exp'],\n",
    "                        input_size=data_tensor.size()[1] * data_tensor.size()[2],\n",
    "                        hidden_size=config['model_hs'] ,\n",
    "                        drop_rate=0)\n",
    "\n",
    "\n",
    "if (config['opt' ]== \"ADAM\"):\n",
    "    optim = Adam(\n",
    "        model.parameters(),\n",
    "        lr=config['lr_base'],\n",
    "        weight_decay=config['wght_decay'],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    optim = SGD(\n",
    "        model.parameters(),\n",
    "        lr=config['lr_base'],\n",
    "        weight_decay=config['wght_decay'],\n",
    "        momentum= config['momentum'],\n",
    "    )\n",
    "\n",
    "sched = LRSchedulerPlugin(\n",
    "    MultiStepLR(optim, [config['lr_milestones_1'],config['lr_milestones_2']], gamma=1.0 / config['lr_factor'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the strategy\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "\n",
    "\n",
    "strategy = ICaRL(\n",
    "    model.feature_extractor,\n",
    "    model.classifier,\n",
    "    optim,\n",
    "    config['memory_size'],\n",
    "    buffer_transform=transforms.Compose([transformData]),\n",
    "    device=device,\n",
    "    fixed_memory=True,\n",
    "    train_mb_size=config['batch_size'],\n",
    "    train_epochs=config['epochs'],\n",
    "    eval_mb_size=config['batch_size'],\n",
    "    plugins=[sched],\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "###  Training Code\n",
    "print(\"Starting experiment...\")\n",
    "evaluationResults = []\n",
    "processingTime = []\n",
    "startingTime = time.time()\n",
    "print(\"startingTime : \",startingTime)\n",
    "for  i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i +1 ]\n",
    "\n",
    "    print(\"Start training on experience \", exp.current_experience)\n",
    "    expTime = time.time()\n",
    "    print(\"starting a new exp time : \",expTime)\n",
    "    val_exps = [e for e in scenario.test_stream][: i +1 ]\n",
    "    strategy.train(exp, num_workers=4)\n",
    "    print(\"End training on experience\", exp.current_experience)\n",
    "\n",
    "    evaluationResults.append(strategy.eval(eval_exps, num_workers=4 ))\n",
    "    print(\"Computing accuracy on the test set\")\n",
    "    expEndTime = time.time()\n",
    "    expDuration = expEndTime - expTime\n",
    "    processingTime.append(expDuration)\n",
    "\n",
    "endTime = time.time()\n",
    "print(\"endTime : \",endTime)\n",
    "print(\"total Processing time :\" ,endTime-startingTime)\n",
    "\n",
    "procTime = endTime-startingTime\n",
    "\n",
    "\n",
    "num_classes = config['nb_exp']\n",
    "evaluationDfColumns = ['Exp', 'testAcc', 'trainAcc']\n",
    "lst = range(0, num_classes)\n",
    "evaluationDfColumns = evaluationDfColumns + [\"testAccExp{:d}\".format(x) for x in lst]\n",
    "\n",
    "evaluationDf = pd.DataFrame(columns=evaluationDfColumns)\n",
    "trainingDf = pd.DataFrame(columns=evaluationDfColumns)\n",
    "\n",
    "for i in range(0, num_classes):\n",
    "\n",
    "    evaluationLine = {}\n",
    "    evaluationLine = {'Exp': i,\n",
    "                        'testAcc': evaluationResults[i]['Top1_Acc_Stream/eval_phase/test_stream/Task000'],\n",
    "                        'trainAcc': evaluationResults[i]['Top1_Acc_Epoch/train_phase/train_stream/Task000']}\n",
    "\n",
    "    for j in range(0, num_classes):\n",
    "        if (j <= i):\n",
    "            evaluationLine[\"testAccExp{:d}\".format(j)] = evaluationResults[i][\n",
    "                \"Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp{:03d}\".format(j)]\n",
    "\n",
    "    new_row = pd.Series(data=evaluationLine)\n",
    "\n",
    "    evaluationDf = evaluationDf.append(new_row, ignore_index=True)\n",
    "\n",
    "evaluationDf.to_csv(BaseSaveDir + \"ICARL_{:d}.csv\".format(runningIdx), index=False)\n",
    "\n",
    "\n",
    "print(\"Ending the  seed \", config[\"seed\"] )\n",
    "print(\"last set training acc:\",evaluationDf['trainAcc'].iloc[-1])\n",
    "print(\"training acc:\",evaluationDf['trainAcc'].mean())\n",
    "print(\"testing acc:\",evaluationDf['testAcc'].iloc[-1])\n",
    "\n",
    "config['trainAccMean'] = evaluationDf['trainAcc'].mean()\n",
    "config['trainAccLast'] = evaluationDf['trainAcc'].iloc[-1]\n",
    "config['testAcc'] = evaluationDf['testAcc'].iloc[-1]\n",
    "config['procTime'] = procTime\n",
    "configDF = pd.DataFrame(config, index=[0])\n",
    "configDF.to_csv(BaseSaveDir + \"ICARL_Config_{:d}.csv\".format(runningIdx), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
